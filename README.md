# Textual-Data-Literc
Data literacy for textual analysis

## Data Litercy 

Digital or data literacy can be defined as a way to think critically about data, or numbers issued by analysis. 

Textual data literacy is the ability to transform automatically big quantities of text into numerical data through applied statistical methods.

The ACRL (Association of College Research Libraries) already in 2015 advised to go beyond information literacy, incorporating also data information literacy to courses addressed to students. 

Moreover nowadays, "Textual retrieval", or the ability to retrieve information from information extracted from texts, is considered relevant, to inferr from textual data analysis trends and patterns about contents.

## Data in general and in the programming language 

Broadly speaking data can be quantitatives or qualitatives, or in other words numbers or texts (unstructured data), howether if we consider the programming language, there are more kind of data, or "data types". 
For instance numbers are "intergers", if whole numbers, or "floats" if they are measured in fractions. 
Text, or textual data can be called "strings", as they consist in letters (for a computer simply signs).

In a "flow control", or the line of commands asking the computer to perform something, the result of the application of boolean operators (AND, OR, NOT) produces two other data types: TRUE or FALSE.

A "list" is a way to store different data types, possibly million of items in a ordered way, and a "data structure" is how information can be stored inside a program.

## Files and files formats

Some kind of data file formats are:

Tabular data, or data organized in raws and colums, CSV files with the (.csv) extension, or Excel files (former proprietory, now an open file format) with the extension .(.xlsx).

Unstructured data, textual data, or text files with the extension (.txt) with only text and no formatting (a word file is a formatted one), Portable Document file with the extension (.pdf),
Images, of images contained in files, or JPG with the extension (.jpg), or (.png)\n", other files used for the data interchange: Markup HyperText Markup Language (.html).

## Why data curation, or "know your data"

Data curation is the activity done on data in order to analyze and store them properly, as for instance: cleaning, processing, munging, archiving, re-use, communicate and share. To perform all those activities in necessary to know where to store data for long term preservation, how to name files (to give metadata), be careful about proprietary formats and their evolution on time, be attentive on how to share data for pourposes of reproducibility .
In the case of textual data the data curation is called "pre-processing" and it aims is to tranform raw data into data ready to be analyzed.

## Computational literacy

It can be a synonim of data litearcy, but computational literacy consider not only data, but software using data, or alternatively customized ways to create "command line" to do analysis autonomously. 

In order to deal with data is necessary some computational literacy, or as Professor Passarotti (Passarotti, 2022) says a "computational" or "automatic" way to think enabling to foresee what it can be done with automation.
Computational literacy is the ability to use automatic analysis devices, knowing how they work and what one can expect from, in order of being able to interpret results duly.

 
## Python literacy, or the "Pythonic way"

A piece of this literacy is all the instructions enabling people to use Phyton as an "empowering" instrument to do customized text analysis. Phyton being a programming language, learning to write codes is equivalent to learn a foreign language.

## Language Models Literacy

AI applications have spread in different domains as for instance in scientific literature searching, this is entailing a new way to do bibliographic search ("systematic literature reviews") by exploring topics (Solveing et al., 2023). The problem is that most of the time services proposing systematic literature reviews are lacking in methodology transparency, frequently algorithms used to do systematic literature review are not open, but proprietary, and in many cases one does not know how the algorithms work and even where the search has been done (on which collection of texts). Huge are the consequences in terms of research accountability and reproducibility.

Because of the recent spread of AI applications, also an AI literacy has become necessary, because knowing how language models works is necessary to understand how their applications propose results and what one can realistically expect from. A piece of  literacy is to let people known that beside proprietary language models there are also open source ones.

For instance Hugging face is a repository of open source language models that can be consulted to have an idea. Web source: https://huggingface.co/

## API literacy

Definition of APIs and their use nowadays.

    "## RAG, Retrieval Augmented Generation pipeline\n",
    "\n",
    "RAG literacy is useful to make LLMs more performant and to avoid hallucinations. In the pipeline the model is trained on specific data (a customized knowledge base) as to use them to answer to the question and not the commonly webscraped source of information. More accurate information used enables to be more precise in the answering.\n",
    
